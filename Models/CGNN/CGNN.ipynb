{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from random import sample\n",
    "import csv\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from pymatgen.core.structure import Structure\n",
    "\n",
    "from data import CIFData, collate_pool, get_train_val_test_loader\n",
    "from model import CrystalGraphConvNet\n",
    "from tools import AtomInitializer, AtomCustomJSONInitializer, Normalizer, GaussianDistance\n",
    "from training import train, validate, mae, cust_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract initialization vector for each element from atom_init.json\n",
    "IDs = pd.read_excel('Unique IDs.xlsx',header = None).values\n",
    "IDs = [IDs[i][0] for i in range(len(IDs))]\n",
    "atomic_features = AtomCustomJSONInitializer('./cifs_dataset31/atom_init.json')\n",
    "crystal_features = {}\n",
    "max_num_nbr = 12\n",
    "dmin = 0\n",
    "step = 0.2\n",
    "radius = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usvai\\anaconda3\\Lib\\site-packages\\pymatgen\\io\\cif.py:1197: UserWarning: Issues encountered while parsing CIF: Some fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: \" + \"\\n\".join(self.warnings))\n"
     ]
    }
   ],
   "source": [
    "# Aggregating features of all atoms for each compound\n",
    "for i in IDs:\n",
    "    crystal = Structure.from_file('./cifs_dataset31/' + i + '.cif')\n",
    "    atom_fea = np.vstack([atomic_features.get_atom_fea(crystal[i].specie.number) for i in range(len(crystal))])\n",
    "    all_nbrs = crystal.get_all_neighbors(radius, include_index=True)\n",
    "    all_nbrs = [sorted(nbrs, key=lambda x: x[1]) for nbrs in all_nbrs]\n",
    "    GDF = GaussianDistance(dmin = dmin, dmax = radius, step = step)\n",
    "    \n",
    "    nbr_fea_idx, nbr_fea = [], []\n",
    "    for nbr in all_nbrs:\n",
    "        if len(nbr) < max_num_nbr:\n",
    "            warnings.warn('{} not find enough neighbors to build graph. '\n",
    "                            'If it happens frequently, consider increase '\n",
    "                            'radius.'.format(i))\n",
    "\n",
    "            nbr_fea_idx.append(list(map(lambda x: x[2], nbr)) + [0] * (max_num_nbr - len(nbr)))              \n",
    "            nbr_fea.append(list(map(lambda x: x[1], nbr)) + [self.radius + 1.] * (max_num_nbr - len(nbr)))\n",
    "                                   \n",
    "        else:\n",
    "            nbr_fea_idx.append(list(map(lambda x: x[2],nbr[:max_num_nbr])))                               \n",
    "            nbr_fea.append(list(map(lambda x: x[1],nbr[:max_num_nbr])))\n",
    "                                        \n",
    "    nbr_fea_idx, nbr_fea = np.array(nbr_fea_idx), np.array(nbr_fea)\n",
    "    nbr_fea = GDF.expand(nbr_fea)\n",
    "    atom_fea = torch.Tensor(atom_fea)\n",
    "    nbr_fea = torch.Tensor(nbr_fea)\n",
    "    nbr_fea_idx = torch.LongTensor(nbr_fea_idx)\n",
    "    crystal_features[i] = [atom_fea,nbr_fea,nbr_fea_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "use_cuda = True\n",
    "is_cuda = use_cuda and torch.cuda.is_available()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFData(crystal_features,'./cifs_dataset31')\n",
    "collate_fn = collate_pool\n",
    "\n",
    "train_loader, val_loader, test_loader = get_train_val_test_loader(\n",
    "    dataset = dataset,\n",
    "    collate_fn = collate_fn,\n",
    "    batch_size = 128,\n",
    "    train_ratio = 0.8,\n",
    "    num_workers = 0, # All workers\n",
    "    val_ratio = 0.1,\n",
    "    test_ratio = 0.1,\n",
    "    pin_memory = is_cuda,\n",
    "    train_size = None,\n",
    "    val_size = None,\n",
    "    test_size = None,\n",
    "    return_test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling 500 data points at random from dataset\n",
    "sample_data_list = [dataset[i] for i in sample(range(len(dataset)), 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input, sample_target, _ = collate_pool(sample_data_list)\n",
    "structures, _, _ = dataset[0] # Extracting only the first element of the data set\n",
    "normalizer_target = Normalizer(sample_target)\n",
    "normalizer_crystal = Normalizer(sample_input[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/3309]\tTime 1.377 (1.377)\tData 0.896 (0.896)\tLoss 8.4212 (8.4212)\tMAE 275.358 (275.358)\n"
     ]
    }
   ],
   "source": [
    "orig_atom_fea_len = structures[0].shape[-1] # Number of features in the atomic feature vector\n",
    "nbr_fea_len = structures[1].shape[-1] # Number of features in the neighbor feature vector\n",
    "crystal_fea_len = structures[3].shape[-1] # Number of additional crystal features\n",
    "\n",
    "model = CrystalGraphConvNet(orig_atom_fea_len, nbr_fea_len,\n",
    "                            atom_fea_len = 50, # First layer of linear transformation before convolution\n",
    "                            n_conv = 3, # Number of convolution layers\n",
    "                            h_fea_len = 100, # Number of units in first hidden layer of fully connected network\n",
    "                            n_h = 2, # Number of fully connected layers\n",
    "                            crystal_fea_len = crystal_fea_len,\n",
    "                            classification = False) # Regression\n",
    "\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "#criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), 0.0001, weight_decay = 0.1)\n",
    "scheduler = MultiStepLR(optimizer, milestones = [100],gamma = 0.1)\n",
    "\n",
    "start_epoch = 1\n",
    "end_epoch = 11 # 10 epochs\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    \n",
    "    # train for one epoch\n",
    "    train(train_loader, model, optimizer, epoch, normalizer_target, normalizer_crystal)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    mae_error = validate(val_loader, model, normalizer_target, normalizer_crystal)\n",
    "\n",
    "    if mae_error != mae_error:\n",
    "        print('Exit due to NaN')\n",
    "        sys.exit(1)\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    best_mae_error = 1e10\n",
    "    \n",
    "    # remember the best mae_eror and save checkpoint\n",
    "    is_best = mae_error < best_mae_error\n",
    "    best_mae_error = min(mae_error, best_mae_error)\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_mae_error': best_mae_error,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'normalizer': normalizer_target.state_dict(),\n",
    "    }, is_best)\n",
    "\n",
    "# test best model\n",
    "print('---------Evaluate Model on Test Set---------------')\n",
    "best_checkpoint = torch.load('model_best.pth.tar')\n",
    "model.load_state_dict(best_checkpoint['state_dict'])\n",
    "test, target = validate(test_loader, model, normalizer_target, normalizer_crystal, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted and compute MAPE\n",
    "plt.scatter(target,test)\n",
    "pred = 10**test\n",
    "target = 10**target\n",
    "total = 0\n",
    "cnt = 0\n",
    "for i in range(len(y_pred)):\n",
    "    total += (abs(target[i] - pred[i])/target[i])*100\n",
    "    cnt += 1\n",
    "print(\"The MAPE is \" + str(round((total/cnt)[0],2)) + \" %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predicted results\n",
    "transform_y_pred = 10**test\n",
    "transform_y_test = 10**target\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook('Full dataset (CGCNN test results).xlsx') \n",
    "worksheet = workbook.add_worksheet()\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "actual = transform_y_test.tolist()\n",
    "prediction = transform_y_pred.tolist()\n",
    "\n",
    "# Iterate over the data and write it out row by row\n",
    "for i in range(len(actual)):\n",
    "    worksheet.write(row, col, actual[i][0])\n",
    "    worksheet.write(row, col + 1, prediction[i])\n",
    "\n",
    "\n",
    "    row += 1\n",
    "\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
